{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.0240568401325\n",
      "75.8800745010376\n",
      "âœ… ìµœì  ëª¨ë¸ ì €ì¥ ì™„ë£Œ! (`best_model.pkl`)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# âœ… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"data/student-por.csv\")\n",
    "\n",
    "# âœ… `G1`, `G2` ë³€í™˜ (í‰ê·  ì„±ì , ë¹„ìœ¨ ê³„ì‚°)\n",
    "df[\"G_avg\"] = df[\"G1\"] + df[\"G2\"]\n",
    "df[\"G_ratio\"] = df[\"G1\"] / (df[\"G2\"] + 1)  \n",
    "\n",
    "# âœ… **6ê°œì›” ê¸°ì¤€ ëˆ„ì  ê³µë¶€ ì‹œê°„ê³¼ ììœ  ì‹œê°„ ê³„ì‚°**\n",
    "df[\"studytime_per_6months\"] = df[\"studytime\"] * 26  \n",
    "df[\"freetime_per_6months\"] = df[\"freetime\"] * 26  \n",
    "df[\"total_hours\"] = df[\"studytime_per_6months\"] + df[\"freetime_per_6months\"]\n",
    "\n",
    "# âœ… **ê³µë¶€ ì‹œê°„ì´ ë§ì„ìˆ˜ë¡ ì„±ì  ìƒìŠ¹ íš¨ê³¼ ì¦ê°€ (ê¾¸ì¤€íˆ ì¦ê°€)**\n",
    "df[\"studytime_boost\"] = np.log1p(df[\"studytime_per_6months\"]) * 5  # ğŸ¯ ë¡œê·¸ ë³€í™˜ìœ¼ë¡œ ì•ˆì •ì„± ì¦ê°€\n",
    "\n",
    "# âœ… **ììœ  ì‹œê°„ì´ ë§ì„ìˆ˜ë¡ ì„±ì  í•˜ë½ íŒ¨ë„í‹° ì ìš© (ì™„ë§Œí•œ ê°ì†Œ)**\n",
    "df[\"freetime_penalty\"] = np.sqrt(df[\"freetime_per_6months\"]) * 1.5  \n",
    "\n",
    "# âœ… **í•™ìŠµ ì‹œê°„ ë¹„ìœ¨ ì¡°ì • (ê¾¸ì¤€íˆ ì¦ê°€)**\n",
    "df[\"studytime_ratio\"] = (df[\"studytime_per_6months\"] / (df[\"total_hours\"] + 1)) ** 1.3  \n",
    "\n",
    "# âœ… í•™ìŠµ ë°ì´í„° êµ¬ì„±\n",
    "X = df[['studytime_per_6months', 'freetime_per_6months', 'G_avg', 'G_ratio', \n",
    "        'total_hours', 'studytime_boost', 'freetime_penalty', 'studytime_ratio']]\n",
    "y = df[['G3']]\n",
    "\n",
    "# âœ… MinMaxScaler ì ìš©\n",
    "scaler_X = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# âœ… Linear Regression í•™ìŠµ\n",
    "regressor_lr = LinearRegression()\n",
    "regressor_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# âœ… XGBoost í•™ìŠµ\n",
    "regressor_xgb = XGBRegressor(\n",
    "    n_estimators=500,  \n",
    "    learning_rate=0.05,  # í•™ìŠµ ì†ë„ ì¡°ì ˆ\n",
    "    max_depth=6,  # íŠ¸ë¦¬ ê¹Šì´ ì¦ê°€\n",
    "    subsample=0.9,  \n",
    "    colsample_bytree=0.9,  \n",
    "    random_state=42\n",
    ")\n",
    "regressor_xgb.fit(X_train_scaled, y_train.values.ravel())\n",
    "\n",
    "# âœ… ëª¨ë¸ í‰ê°€\n",
    "y_pred_test_lr = regressor_lr.predict(X_test_scaled)\n",
    "y_pred_test_xgb = regressor_xgb.predict(X_test_scaled)\n",
    "test_score_lr = r2_score(y_test, y_pred_test_lr) * 100\n",
    "test_score_xgb = r2_score(y_test, y_pred_test_xgb) * 100\n",
    "print(test_score_lr)\n",
    "print(test_score_xgb)\n",
    "# âœ… ìµœì  ëª¨ë¸ ì„ íƒ\n",
    "best_model = regressor_xgb if test_score_xgb > test_score_lr else regressor_lr\n",
    "joblib.dump(best_model, \"best_model.pkl\")\n",
    "joblib.dump(scaler_X, \"scaler_X.pkl\")\n",
    "\n",
    "print(f\"âœ… ìµœì  ëª¨ë¸ ì €ì¥ ì™„ë£Œ! (`best_model.pkl`)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# âœ… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv(\"data/student-por.csv\")\n",
    "\n",
    "# âœ… G3ì„ ì˜ˆì¸¡í•˜ëŠ” ë³„ë„ì˜ ëª¨ë¸ì´ ì¡´ì¬í•˜ë¯€ë¡œ, í•´ë‹¹ ëª¨ë¸ì˜ ì¶œë ¥ì„ ê°€ì ¸ì™€ ì‚¬ìš©í•œë‹¤ê³  ê°€ì •\n",
    "\n",
    "# âœ… ì¥í•™ê¸ˆ ê°€ëŠ¥ ì—¬ë¶€ ì„¤ì • (ì˜ˆ: G3 >= 15ì´ë©´ ì¥í•™ê¸ˆ ê°€ëŠ¥, ì•„ë‹ˆë©´ ë¶ˆê°€ëŠ¥)\n",
    "df['scholarship'] = (df['G3'] >= 15).astype(int)\n",
    "\n",
    "# âœ… ì‚¬ìš© ë³€ìˆ˜ ì„ íƒ (âš ï¸ G3ì„ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©)\n",
    "X = df[['G3']]  # ì¥í•™ê¸ˆ ëª¨ë¸ì—ì„œëŠ” G3ì„ ì…ë ¥ê°’ìœ¼ë¡œ ì‚¬ìš©\n",
    "y = df['scholarship']\n",
    "\n",
    "# âœ… ë°ì´í„° ì •ê·œí™”\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# âœ… ë°ì´í„° ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# âœ… ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ (ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ê¸° ì‚¬ìš©)\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# âœ… ëª¨ë¸ í‰ê°€\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"âœ… ëª¨ë¸ ì •í™•ë„: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# âœ… ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥\n",
    "joblib.dump(model, \"scholarship_model.pkl\")\n",
    "joblib.dump(scaler, \"scholarship_scaler.pkl\")\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ ë° ë³€í™˜ê¸° ì €ì¥ ì™„ë£Œ!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
